Doctors have turned to scientific studies for guidance on talking with patients, but the results have largely left them guessing. COMMENT I'm afraid I have some bad news. The above sentence probably wasn't pleasant to read. Maybe it gave you a sinking feeling in the pit of your stomach or made your blood pressure spike. But in medicine, this ominous phrase is often used as a "warning shot" to give patients the chance to brace for the impact of oncoming news before it is delivered. Does it work? It depends on who you ask. Every physician must occasionally deliver bad news, be it tragic ("you may never walk again") or merely uncomfortable to discuss ("you have chlamydia"). As a research assistant at one of the top teaching hospitals in the United States, I've come to realize how little we understand about teaching doctors to communicate with patients and deliver hard-to-swallow information. Recently, doctors have been looking to the scientific community for objective guidance on the best way to handle distressing conversations, but current research - complicated by difficult ethical constraints and technical limitations - can't always tell us genuinely useful information. For example, consider a 2012 study published in the journal Patient Education and Counseling, in which healthy volunteers watched an online video of a physician who pretended to diagnose them with Bekhterev's disease, a type of arthritis that affects the spine. The doctor used affirmations in some videos ("this news is bad") and negations in others ("this news is not good"). He also alternated between framing the news in a positive light ("most patients find it easy to live with this disease") and a negative one ("most patients find it difficult to live with this disease"). Afterwards, participants were asked a series of questions, including whether they would've followed the doctor's treatment recommendations if they had actually been ill. Like what you're reading? Sign up for our free weekly newsletter or donate to support great journalism. The authors of the study concluded that doctors should use affirmations to deliver positively framed news and negations to deliver negatively framed news. However, the communication preferences of healthy volunteers are likely distinct from those of actual patients, and a person's reaction to a pre-recorded video can only tell you so much about real-world communication in a hospital setting. In addition, consumers can't even accurately predict whether they would be more or less likely to buy ketchup if it were sold to them in a different bottle. Therefore, I'm sceptical about conclusions that are drawn based on the way that these subjects imagined they would respond to a doctor's advice about a disease they didn't actually have. In a similar vein, consider a 2007 study published in the journal Palliative Medicine that looked at the effects of physician posture during difficult conversations. In this experiment, volunteers watched two nine-minute videos of a middle-aged male doctor breaking bad news to an elderly female cancer patient. The scenes were identical, except that the physician stood in one and sat in the other. The viewers reported that the sitting physician seemed more compassionate than the standing physician. However, it is not uncommon for study participants to treat this kind of situation - either consciously or unconsciously - as a kind of "game": They attempt to figure out what the experimenters are testing, guess at the desired outcome, and then modify their answers accordingly. This phenomenon, a type of response bias, may have corrupted the study results - especially given that the difference between the two consultations was obvious. Ultimately, the authors of the study conclude: "Sitting is the clear preference for physician posture... but some patients prefer their physician to stand and many have no preference." Well, glad we cleared that up. While the research community has struggled to solve the bad news problem, medical schools have tried to develop and teach their own strategies. Most often, they attempt to break down communication into discrete steps that can be performed and evaluated the same way as more traditional clinical skills. A popular example is the Spikes procedure, which counsels doctors to pay attention to setting, assess the patient's perception, obtain an invitation to share information, give knowledge, address emotions, and close with a summary. However, the Spikes protocol and others like it are based on expert opinion rather than empirical evidence, and their instructions are sometimes ambiguous or contradictory. In addition, although step-by-step instruction tends to improve medical students' performance in academic training scenarios - where they are judged on oddly specific criteria like acknowledging "patient feeling without specifically naming it" - a 2010 systematic review published in the European Journal of Cancer Care found no evidence to suggest that these training exercises translate into improved patient outcomes. Read more: A virtual attitude adjustment: Why the quest for kinder nurses just got high tech. Moreover, step-by-step approaches can backfire. For example, one study found that patients who spoke with doctors and nurses that had recently undertaken a communications training course actually showed increased symptoms of depression compared with patients who spoke to caretakers without this training, research featured in the Journal of the American Medical Association found. Based on my own experiences, I suspect this may be because communication protocols sometimes make health care practitioners seem insincere. Doctors may not have determined a foolproof way to deliver bad news, but they've certainly found plenty of wrong ways. Physicians who are uncomfortable with breaking bad news commonly stall in their delivery or begin speaking in medical jargon, which can cause confusion. Researchers at the University of Sussex in the United Kingdom described one case where an oncologist told an elderly patient that "there are signs that things are progressing" and recommended that the patient stop receiving chemotherapy. When the patient was asked about the conversation afterwards, he replied, "It's good news," mistaking the doctor's reference to "progress" as an affirmation that his chemo had worked. Unsurprisingly, patients are also not fond of a callous bedside manner. In one study where subjects watched videos of physicians talking with patients in various communication styles, the viewers reported unanimous disdain for the so-called "rough and ready expert" who responded to his patients with brusque, unsympathetic comments like, "[You're] afraid!? Why!?" I wish I could tell you that there was a science to delivering unpleasant news and that it could be done in a few clear, easy steps, like suturing a wound. But human emotions are too complex for that. A physician once told me that, after he informed a man that his sister had died in an unexpected car accident, that man became overwhelmed with grief and punched him directly in the face. I'm not sure an easy-to-remember acronym would have helped in this situation. Read more: When the sorrow won't end and why chronic grief could be a medical condition The bad news about breaking bad news is that there is no one right way to do it. Behavior that feels comforting or appropriate to one person will not necessarily elicit the same reaction from others. Efforts to develop a "one-size-fits-all" solution to the bad news problem may be a waste of everyone's time. My suggestion? Instead of telling doctors exactly what to do or say - like "express personal regrets" or "ask about feelings" - perhaps we should focus on training them to avoid the habits that we know are bad, like stalling and using medical jargon. Then, each physician can find the individual techniques that suit them and their particular patients best -and result in the fewest number of punches to the face. Morgan Pantuck is a research assistant in the Department of Urology at Weill Cornell Medicine. She'll begin working on her MD/PhD. in Autumn of 2019. This is an edited version of an article originally published on Undark. Read the original article.